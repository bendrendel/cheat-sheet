<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    <a href="../index.html">Home</a>
    <h1>Descriptive Statistics</h1>

    <h2>Variables</h2>
    <ul>
        <li><strong>Variables</strong> Most data sets can be represented as a table, where each row is called an observation, and each column is called a variable.  Each cell contains a value.  Variables generally are either quantitative or categorical.</li>
        <li><strong>Quantitative Variables</strong> Quantitative variables are information about an observation that can only be described by numbers, usually counts or measurements of something.  They are well suited to mathematical analysis.  They are generally either discrete or continuous.  Sometimes something like age might be discrete or continuous, if it is the nearest age in years it is discrete, but if it age in years with a decimal representing fractions of a year then it is continuous.</li>
        <ul>
            <li><strong>Discrete Quantitative Variables</strong> These are variables that can only have integer values and represent counts of things, such as number of children in a family, or number of coin flips made</li>
            <li><strong>Continuous Quantitative Variables</strong> These are variables that generally represent measurements like length, weight and age that theoretically can take on any real number.</li>
        </ul>
        <li><strong>Categorical Variables</strong> These variable group together or classify the observations and can either be ordinal if they have an order, or nominal if not. You can use the .unique() method on a pandas data frame to get the unique values in a column which is often handy for categorical variables, e.g. <code>print(list(my_data_frame['my_column'].unique()))</code> It is often helpful to know the counts of unique values with <code>my_data_frame['my_column'].value_counts()</code> which returns all unique values with a count of how many times the appear ordered descending.  Or it is helpful to know the relative frequency of each unique value (counts divided by total number of values) with <code>my_data_from['my_column'].value_counts(dropna = False, normalize = True)</code> which will return a 'table of proportions', i.e each unique value with its relative frequency. The dropna is True by default if excluded and that will ignore missing (like NaN) values in the dataset thus bumping up the relative frequency of all other values if there are misssing values, setting it to false will include missing values as a category in the output and show their relative frequency.</li>
        <ul>
            <li><strong>Ordinal Categorical Variables</strong> These variables are qualitative but have some intrinsic order to them, like a survey result of "strongly disagree, disagree, neutral, agree, strongly agree", has an order to them, as would something like seniority "junior, mid, senior, executive", etc.  However, the 'distance' between values is not really defined, which is a key part of what makes them non-quantitative.  You can have a mode for this type of data, and you can have statistics that rely on order like median, ranges, percentiles and quantiles. However, the mean (and any other statistics that rely on it like variance) doesn't make sense because it intrinsically rely on the distance between values being defined.  For example you could have an education level variable that is 'elementary', 'middle', 'highschool', 'some college', 'college', and although it is ordered, the distance between points is not consistent and well-defined, so a mean would not make sense.  ID fields are technically categorical even if they are represented as an integer.  In a pandas data frame it is helpful to set the column as categorical so you can give it an ordering. To do this, you need to create a list of all the values in the column in the correct order, ascending, and then use <code>my_data_frame['my_ordinal_variable'] = pd.Categorical(my_data_frame['my_ordinal_variable'], correct_order, ordered=True)</code>, where correct_order is the list of values in order.  Now the column will have a property cat.codes that allows you to do things like calculate the median with numpy, e.g.  <code>median_index = np.median(my_data_frame['my_ordinal_variable'].cat.codes)</code>, which will return an integer that can be converted to the actual value with <code>correct_order[int(median_index)]</code></li>
            <li><strong>Nominal Categorical Variables</strong> These variables are qualitative and have no instrinsic order like states in the U.S., brands, colors, favorite food, etc.  These often have a unique value for every observation like a name or email address. A Binary Variable is a special kind of nominal variable that has exactly two possible values, such as Is On? or Day or Night? and often take on True or False as the value.  You can't produce statistics for these variables that depend on ordering, like mean, median, variance, standard deviation, ranges, IQR, or percentiles.  However, you can have a mode, the most frequently occuring value.  Binary Variables can use some tricks, e.g. if they are coded to 1 and 0, or True and False, then <code>np.sum(my_data_frame['my_binary_variable'])</code> will return the number of 1's or Trues (becuase True gets coerced to 1 and False to 0), so it is a way to count values. Similarly, <code>np.mean(my_data_frame['my_binary_variable'])</code> would return the relative proprotion of 1's or Trues because the mean will add all the 1's or Trues together then divide by the total number of values.  It can be handy to convert other columns to binary like <code>isAlive = nyc_trees['status'] == 'Alive'</code>, where the 'status' column has many different categories ('Dead', 'Sick', etc.) but you just want to know if it is 'Alive' or not.</li>
        </ul>
    </ul>

    <h2>Central Tendency</h2>
    <ul>
        <li><strong>Mean</strong> Also often referred to as the average, and represented by x with a bar over it.  It is the sum of all the observations x1 + x2 + ... + xn, divided by the number n of observations. The python numpy library (include <code>import numpy as np</code> ) has .average() and .mean() methods that accept a list of values as input and returns the mean.  The .average() method can optionally accept a weights parameter to calculate a weighted mean.</li>
        <li><strong>Median</strong> The median tells you the value for which half the values in a data set are larger and half are smaller.  The data set must first be sorted, then the value in the middle of the sorted data set is the median.  If there are an even number of values in the data set, then it is reported as both of the middle two values or their average.  Numpy's .median() method takes a list of values and outputs the median, it will average the two middle values if the data set has an even number of values.</li>
        <li><strong>Mode</strong> The mode tells you the most frequently occuring value found in a dataset, and there can be multiple modes if the data set has more than one value with the same max frequency.  The python SciPy library (include <code>from scipy import stats</code> at the top of the file) has a stats.mode() method that takes a list of values and returns an object that contains the mode value and the number of values that equals the mode.  If there are multiple modes, then it always returns the lowest valued mode. For categorical variables, the pandas library (<code>import pandas as pd</code>) has a method that will take a column from a data frame and return the count of each unique value in the column in descending order, using <code>my_dataframe['my-categorical-column'].value_counts()</code>, you could tack on <code>.index[0]</code> to return only the first row which will be the mode.</li>
    </ul>

    <h2>Spread</h2>
    <ul>
        <li><strong>Variance</strong> The variance is a measure of how spread out a data set is, and is calculated as the average of the squared difference between each data point and the mean. It is usually notated as σ<sup>2</sup>.  The Numpy python library (<code>import numpy as np</code>) has a .var() method that takes a list of values and returns the variance.</li>
        <li><strong>Standard Deviation</strong> The standard deviation is simply the square root of the variance, and is representd by σ.  This is generally easier to interpret than variance because variance will have a squared unit, whereas standard deviation will have the same unit as the mean and the data itself.  The numpy python library has a .std() method that takes a list of values and returns the standard deviation. For normally distributed data, 68.3% of the values are within 1 standard deviation of the mean, 95.5% are with two, and 99.7% are within three.</li>
        <li><strong>Percentiles</strong> A percentile is a value below which (or at or below which) a given percentage of the values in a data set are found. The median is the 50th percentile.  The 10th percentile would be the value below which 10% of the observations are found, likewise the 90th percentile would be the value below which 90% of the observations are found.  You can use this to define ranges such as knowing 80% of the values lie between the 10th percentile and 90th percentile.  The percentile rank of a value in the data set is what percentage of values in the data set lie below the given value. This is a handy way of understanding the spread of ordinal categorical data, which you can't define variance or standard deviation on to help you understand spread.  Numpy has a percentile method that can take a list of values and an integer for the percentile you want, and it will return the value where that percentile lies.  You can use it with a data frame column, and on a categorical column that you've defined as such using the pandas Categorical() method.  e.g. <code>tenth_perc_ind = np.percentile(df['education'].cat.codes, 10)</code></li>
        <li><strong>Interquartile Range (IQR)</strong> This is the middle 50% of values in a dataset, defined by the range minimum of the 25th percentile and the range maximum of the 75th percentile.</li>
    </ul>
</body>
</html>