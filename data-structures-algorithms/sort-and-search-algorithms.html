<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sort and Search Algorithms</title>
</head>
<body>
    <a href="../index.html">Home</a>
    <h1>Sort and Search Algorithms</h1>
    
    <h2>Bubble Sort</h2>
    <ul>
        <li>Bubble Sort is a common simple sorting algorithm.  It compares subsequent pairs of adjacent elements in an unsorted list starting with the first two elements and swaps them if the first element is larger than the second.  This forces the largest element in the list
            to end up at the end of the list.  This is then repeated on the remaining unsorted elements, moving the second largest element to the second to last position in the list.  This continues until no more swaps occur indicating the list is sorted.
        </li>
        <li>To swap elements, you'll need a temporary variable to hold one of the elements or a language that supports multiple assignment in one line</li>
        <li>The runtime is O(n^2).  Consider this requires you to make n-1 comparisons (and possible swaps) when you go through a list of length n once.  You have to go through the list making swaps up to n-1 times to get everything ordered.  But each time you go through, the number of comparisons (and possible swaps) needed decreases by one.  Calculating the actual execution count is something like below. Up to n-1 times through the list making comparisons and swaps (x2 operations), but decreasing the number of items by one each round:
        </li>
        <ul>
            <li>
                <pre>
                                    n-1 terms
                    2[(n-1)+(n-2)+(n-3)+...+(n-(n-2))+(n-(n-1))]
                    =2[(n-1)+(n-2)+(n-3)+...+n-(n-2)+n-(n-1)]

                    n even
                    2[(n-1)+(n-2)+...+(n-n/2)+...+n-(n-2)+n-(n-1)]
                    =2[n-n/2+n*(n/2-1)]
                    =2[n(1-1/2+n/2-1)]
                    =2[n(n/2-1/2)]
                    =2[n((n-1)/2)]
                    =n^2-n

                    n odd
                    2[((n-1)/2)*n]
                    =n^2-n                    
                </pre>
            </li>
        </ul>
        <li>Bubble sort doesn't have a great big O, but it has a good big omega (Ω) of Ω(n), because in the best case scenario, the list is already sorted, so the algorithm just loops once through the list making comparisons, realizes no swaps were made and quits.  This makes bubble sort a good choice if you know a list is nearly fully sorted.</li>
        <li>Example implementation with swap helper function:
            <code><pre>
                const swap = (arr, indexOne, indexTwo) => {
                    const temp = arr[indexTwo];
                    arr[indexTwo] = arr[indexOne];
                    arr[indexOne] = temp;
                };

                const bubbleSort = input => {
                    let swapCount = 0
                    let swapping = true;
                    
                    while (swapping) {
                        swapping = false;
                        for (let i = 0; i &lt input.length - 1; i++) {
                            if (input[i] > input[i + 1]) {
                                swap(input, i, i + 1);
                                swapCount++;
                                swapping = true;
                            }
                        }
                    }
                    console.log(`Swapped ${swapCount} times`);
                    return input;
                };
            </pre></code>
        </li>
    </ul>

    <h2>Merge Sort</h2>
    <ul>
        <li>Merge sort is a sorting algorithm that breaks the input down and then rebuilds it</li>
        <ul>
            <li>1. Split: Cut the list in half repeatedly until you are down to single elements</li>
            <li>2. Merge: Now merge the neighboring single elements into two element lists in order from smallest to largest. Continue merging the lists by comparing the leftmost elements and adding the smallest to the merged list, then comparing the remaining leftmost elements and adding the smallest to the merged list, and so on.</li>
        </ul>
        <li>It has runtime O(n*log n) with no variability (doesn't matter if list is already nearly sorted).  It has space complexity of up to O(n)</li>
        <li>Example implementation: 
            <code><pre>
                const mergeSort = (startArray) => {
                    const length = startArray.length;
                    if (length === 1) {
                        return startArray;
                    }
                    
                    const mid = Math.floor(length / 2);
                    const leftArray = startArray.slice(0, mid);
                    const rightArray = startArray.slice(mid, length);

                    return merge(mergeSort(leftArray), mergeSort(rightArray))
                }

                const merge = (leftArray, rightArray) => {
                    const sortedArray = [];
                    while (leftArray.length > 0 && rightArray.length > 0) {
                        if (leftArray[0] &lt rightArray[0]) {
                            sortedArray.push(leftArray.shift());
                        } else {
                            sortedArray.push(rightArray.shift());
                        }
                    }
                
                    return sortedArray.concat(leftArray).concat(rightArray);
                }
            </pre></code>
        </li>
    </ul>

    <h2>Quicksort</h2>
    <ul>
        <li>A recursive sorting method</li>
        <ul>
            <li>1. Partition: Pick a 'pivot element' from the list, then reorder the list into two partitions, one with elements less than the pivot element, and one with elements greater than the pivot.  Elements equal to the pivot could go in either partition.</li>
            <li>2. Recurse: Now partition the partitions from the step above, reordering elements in the list, and continue until the partitions are only one element, meaning the whole list will be sorted</li>

        </ul>
        <li>Picking the pivot element:</li>
        <ul>
            <li>One good way to pick the pivot element is at random instead of say, always picking the first element.  If you always pick the first element, the algorithm would perform badly on lists that are already sorted because one partition would have all the elements and the other would have just one.  Picking at random will mean that no particular data set will perform badly.</li>
            <li>Another good method is to take the median of the first, middle, and last elements in the list, which tends to create uniform partitions</li>
        </ul>
        <li>Runtime</li>
        <ul>
            <li>The worst case runtime is O(n^2) and the average case is O(n*log n).  The worst case is so uncommon that usually it is thought of as O(n*log n)</li>    
            <li>The worst case occurs when the pivot element is always the min or max of the list, and thus each time you partition you end up with everything in one partition, this would require n partitioning steps, and for each partition you would have n comparison and swap steps, making for n^2</li>
            <li>The best case occurs when the pivot element is always the median so you end up with equal partitions each time you partition, this would cut the list in half with each partition and get down to 1 element in log2 N steps.  Then the merge step at each level would be n operations, making for n*log n</li>
        </ul>
        <li>Example implementation:
            <code><pre>
                const quicksort = (array, leftBound = 0, rightBound = array.length - 1) => {
                    if (leftBound &lt rightBound) {
                        const pivotIndex = partition(array, leftBound, rightBound);
                        quicksort(array, leftBound, pivotIndex - 1);
                        quicksort(array, pivotIndex, rightBound);
                    }
                    return array;
                }

                const partition = (array, leftIndex, rightIndex) => {
                    const pivot = array[Math.floor((rightIndex + leftIndex) / 2)];
                    while (leftIndex $lt= rightIndex) {
                        while (array[leftIndex] &lt pivot) {
                            leftIndex++;
                        }
                        while (array[rightIndex] > pivot) {
                            rightIndex--;
                        }
                        if (leftIndex &lt= rightIndex) {
                            swap(array, leftIndex, rightIndex);
                            leftIndex++;
                            rightIndex--;
                        }
                    }
                    return leftIndex;
                }

                const swap = (arr, indexOne, indexTwo) => {
                    const temp = arr[indexTwo];
                    arr[indexTwo] = arr[indexOne];
                    arr[indexOne] = temp;
                }
            </pre></code>
        </li>
    </ul>

    <h2>Binary Search</h2>
    <ul>
        <li>This is a way of searching through a sorted data set.  It gives a runtime of log n by cutting the list in half with each iteration, meaning at worst it would have to cut it in half again and again until it gets down to 1 element which would take log n iterations.  This is instead of a linear search method that would have a runtime of n, when the order of the list is not known or known to be out of order.</li>
        <li>Binary Search Trees are a binary tree data structure, where every left child node is less than or equal to the parent, and every right child node is greater than or equal to the parent.</li>
        <li>It is a recursive algorithm that looks at the middle value of a sorted list.  If it matches what is searched for then it is done, otherwise the same algorithm is applied to the left half of the list if the searched for value is less than the middle value, or it is applied to the right half of the list if the search for value is greater than the middle value.  This is repeated until the search for value is found.</li>
        <li>Example implementation:
            <code><pre>
                const binarySearch = (arr, target) => {
                    let left = 0;
                    let right = arr.length;
                    
                    while (right > left) {
                        const indexToCheck = Math.floor((left + right) / 2);
                        const checking = arr[indexToCheck];
                        console.log(indexToCheck);
                    
                        if (checking === target) {
                            return indexToCheck;
                        } else if (checking &lt target) {
                            left = indexToCheck + 1;
                        } else {
                            right = indexToCheck;
                        }
                    }
                    
                    return null;
                }
            </pre></code>
        </li>
    </ul>

    <h2>Graph Traversal</h2>
    <ul>
        <li>There are many ways to traverse/search through a graph, but depth-first search (DFS) and breadth-first search (BFS) are the two most common general approaches</li>
        <li>The worst-case O(n) runtime for both is that every single vertex is visited and every edge is traversed between those vertices, thus O(vertices+edges).</li>
    </ul>

    <h3>Depth-First Search</h3>
    <ul>
        <li>DFS Continues down a single path until reaching the end.</li>
        <li>It is helpful when determining if a path exists at all between two vertices. Can be used to solve problems that have a singular correct answer (a path between the start state and end state) such as a Soduko puzzle. It is best for long graphs with few connections.</li>
        <li>Perhaps the most common implementation uses recursion (see example implementation below).</li>
        <li>Another implementation uses a list of all visited vertices and a stack of vertices in the current path.  When a vertex is visited it is added to the list of visited vertices.  With every step, we add the visited vertex to the stack. (The stack starts with the vertex we are starting from.) The vertex at the top of the stack is our current vertex, and we pick an adjacent vertex that isn't in the visited list to move to next.  We add that next vertex to the stack (and the list of visited vertices) and repeat until the current vertex has no adjacent unvisited vertices (i.e. all of its adjacent vertices are in the visited list). At this point, we pop off the current vertex from the stack, making the previous vertex the current one, and then try to visit an unvisited vertex from there.  If there are none, then we pop that off the stack and try again.  This is repeated, until some target vertex is found, or the stack is completely empty indicating all vertices have been visited.</li>
        <li>DFS can be used to get a list of all vertices in a graph, but there are several ways of ordering this, commonly:</li>
        <ul>
            <li>Preorder: This is the order in which vertices are added to the visited vertices list.  It lists the vertices as they were visited by the algorithm, starting at the origin and going down each path explored.</li>
            <li>Postorder: This is the order in which vertices are popped from the stack.  So, the first vertex will be at the end of the first path visited by the algorithm, when the algorithm first starts to back up and pop vertices off the stack. The last element will be the vertex you started the algorithm from.  This is the order in which vertices are "fully explored" by the algorithm.</li>
            <li>Reverse-postorder: AKA Topological sort, this is simply the reverse of the postorder list. So the first element of this list will be the vertex the algorithm started from.</li>
        </ul>
        <li>Example implementation, this could be a method on the Graph data structure developed on the data structure page. It uses a recursive implementation instead of the stack implementation. Start is a vertex from a graph (e.g. myGraph.vertices[0])
            <code><pre>
                const depthFirstTraversal = (start, callback, visitedVertices = [start]) => {
                    callback(start);

                    start.edges.forEach((edge) => {
                        const neighbor = edge.end;

                        if (!visitedVertices.includes(neighbor)) {
                            visitedVertices.push(neighbor);
                            depthFirstTraversal(neighbor, callback, visitedVertices);
                        }
                    });
                };
            </pre></code>
        </li>
    </ul>

    <h3>Breadth-First Search</h3>
    <ul>
        <li>BFS checks every neighboring vertex before moving down another level of depth.</li>
        <li>It is helpful when looking for the shortest path between two vertices. It's inefficient if just looking for whether a path exists at all. It is better for densley connected graphs.</li>
        <li>One implementation uses a list of all visited vertices and a queue of vertices.  Whenever a vertex is visited it is add to the list of visited vertices.  With every step, the vertex is added to the queue (the queue starts with the vertex we start from).  The vertex at the head of the queue is the current vertex and each of its adjacent vertices are checked against the visited vertex list, and if they haven't been visited yet, are added to the queue and the list of visited vertices.  Once the current vertex has no more unvisited adjacent vertices, it is dequeued.  Now the process repeats for the new head of the queue.  This repeats until the target vertex is found or the queue is completely empty indicating all vertices have been visited.</li>
        <li>Example, implementation, relying on the graph data structure and the queue data structure developed on the data strucuture page.  This simply prints out vertices as they are visited, but could be modified to accept a callback instead.
            <code><pre>
                const breadthFirstTraversal = (start) => {
                    const visitedVertices = [start];
                    const visitQueue = new Queue();
                    visitQueue.enqueue(start);

                    while(!visitQueue.isEmpty()) {
                        const current = visitQueue.dequeue();

                        console.log(current.data);

                        current.edges.forEach((edge) => {
                            const neighbor = edge.end;

                            if (!visitedVertices.includes(neighbor)) {
                                visitedVertices.push(neighbor);
                                visitQueue.enqueue(neighbor);
                            }
                        });
                    }
                };
            </pre></code>
        </li>
    </ul>

    <h3>Dijkstra's Algorithm</h3>
    <ul>
        <li>This finds the shortest path from a given vertex to every other vertex in a weighted graph, by using BFS and keeping track of the total weight of paths as it goes.</li>
        <li>Helpful for finding the quickest route, or least costly weighted route from one vertex to another in a weighted graph.</li>
    </ul>
</body>
</html>