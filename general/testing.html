<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Testing</title>
</head>
<body>
    <a href="../index.html">Home</a>
    <h1>Testing</h1>

    <h2>Terminology</h2>
    <ul>
        <li><strong>Software Testing </strong>Assessing the completeness and quality of computer software,
            usually by comparing actual behavior/outcome to expected behavior/outcome.</li>
        <li><strong>Bugs </strong>An error, fault, or flaw making software behave in an unexpected way.</li>
        <li><strong>Manual Testing </strong>Testing done by a human interacting with the system</li>
        <li><strong>Automated Testing </strong>Testing done by software interacting with the system.
            This is faster and more reliable than manual testing and can be done more frequently, 
            often after every significant change to the software.  Developers use test frameworks to organize
            automated tests.</li>
        <li><strong>Test Code </strong>The code written to test software, in contrast to implementation
            code that is the code of the software itself.  Often stored along with implementation code.
            e.g. index.js is the implementation code and in the same folder is index-test.js with test code</li>
        <li><strong>Test Suite </strong>A collection of tests for an application.  A good test suite is maintainable, complete, fast, isolated, reliable, and expressive (MC-FIRE)</li>
        <ul>
            <li>Fast: Fast tests encourage the developer to run tests more often and save time, integration tests generally take longer than unit tests, so a test suite that is heavy on integration tests will be slower</li>
            <li>Complete: A test suite that cover 100% of your code base will give you confidence the program is working correctly</li>
            <li>Reliable: The test suite gives the same output for the same version of the program, i.e. it doesn't fail one time and then pass the next</li>
            <li>Isolated: Tests don't make changes that persist when the test is done running, which could impact other tests or have other unexpected results</li>
            <li>Maintainable: Well-organized so it is easy to add, edit, and remove tests, encouraging completeness</li>
            <li>Expressive: Tests should be descriptive of functionality tested, which effectively documents the purpose of the software</li>
        </ul>
        <li><strong>Documentation </strong>Any content separate from implementation code explaining how it
            works or how to use it.  Tests can be a form of documentation that is unique in that it is
            both readable by humans and computers to confirm it works as described.</li>
        <li><strong>Coverage </strong>Refers to the scope of what is tested. Often testing only covers functionality - i.e. meeting the requirements.  But testing could expand coverage to security, ease of use, and speed</li>
        <ul>
            <li>Code Coverage: This refers to automated tests, and the extent to which they test every area of code</li>
            <li>Test Coverage: This refers to the QA team testing that the software meets the requirements, and the extent to which it tests all the requirements</li>
            <ul>
                <li>Product Coverage: The extent to which all areas of the product are tested</li>
                <li>Risk Coverage: The extent to which possible risks have been tested for</li>
                <li>Requirements Coverage: The extent to which all requirements have been tested</li>
            </ul>
        </ul>
        <li><strong>Regression </strong>When previously tested functionality no longer passes the tests. Can
            happen when new features are implemented.</li>
        <li><strong>Mock Testing </strong>This is when you use a fake version of an internal or external service (e.g. JSON from an API), for testing purposes. This is good to use when possible to save time when running the test.</li>
        <li><strong>Stub Testing </strong>Similar to mock testing, except you only fake some portion of the internal or external service that is specifically needed for the test.  Like mock testing, this is good to use to save time when running the test.  An example is instead of creating an actual error condition by e.g. creating a corrupt file programmatically and then testing what happens when your program tries to read it, you could stub the file system with some functionality that returns the error code for a corrupt file and feed that to your test, instead of actually creating the corrupt file.</li>
    </ul>

    <h2>Test Driven Development (TDD)</h2>
    <p>A development method that writes test code to define program behavior before implementation code, and only writes implementation code in response to failed tests, addressing one failure at a time.</p>
    <p>Phases of test-drive development:</p>
    <ol>
        <li><strong>Add a test</strong> Convert requirements to tests, before code is written</li>
        <li><strong>Run all tests - fail</strong> The new tests should fail because the requirements haven't been met yet</li>
        <li><strong>Write simplest code to pass test</strong> Inelegant, hard-coded is fine</li>
        <li><strong>Run all tests - pass</strong> Revise code until all tests pass</li>
        <li><strong>Refactor</strong> Now make the code more logical, etc.</li>
        <li><strong>Repeat</strong> Repeat this process for every new piece of functionality, generally using unit tests</li>
    </ol>
    <p>This is often simplified as:</p>
    <ol>
        <li><strong>Red: </strong>Write tests to describe how code should behave, tests fail (red) because code doesn't meet requirement</li>
        <li><strong>Green: </strong>Write the minimum possible code to address the test's error message.  Repeat until all tests pass (green).  e.g. the object you are testing doesn't exist (reference error) so you create the object.  Then the method in the object doesn't exist so you create the method.  Then the method returns undefined, so you make it return the hard-coded expected result, now the test passes.</li>
        <li><strong>Refactor: </strong>Refactor code while testing often to ensure it stays green, and backtracking if it doesn't. This includes refactoring both test code and implementation code.  e.g. you may refactor your test code to be broken into setup/exercise/verify phases. You may add an additional test that feeds your method a different input expecting a different result and see that your method fails the test because it is returning the hard-coded expected result of the previous test. This forces you to refactor the implementation code to return a dynamic value based on input.  You might then write a test for edge cases, like providing the wrong data type as input or an empty array as input, and let that fail and guide refactoring of implementation code.  You may also simply refactor implementation code to make it more concise, reduce duplication, use more efficient methods, etc.  You may or may not need to refactor at all in this step, depending on the complexity of the functionality and testing.</li>
    </ol>

    <h2>Testing Heirarchy</h2>
    <p>Testing generally breaks down to Unit Testing, Integration Testing, and UI Testing.  Unit/Component Testing is the fastest and cheapest testing and is done often.  You move up the heirarchy only as previous tests are exhuasted, as higher up tests are slower and more resource expensive.</p>
    <h3>Unit/Component Testing</h3>
    <ul>
        <li>Automated tests written and run by developers, testing small units of code, such as a single class, a function, a module, a method, etc.</li>
        <li>Needs to be used in conjuntion with integration testing, and other tests that test functionality of units working together</li>
        <li>Expect Unit Tests to evolve as the implementation code evolves and implementation details change, unit test code is not as static as higher level tests that test overall functionality that doesn't change as much.</li>
        <li>Can be used as a design-specification, essentially they define what needs to be built and how it should work and can simultaneously be
            used to test if requirements are met.
        </li>
        <li>Unit Testing is fast and cheap, and you should rely heavily on these in your test suite</li>
    </ul>

    <h3>Contract Testing</h3>
    <ul>
        <li>When two services integrate with each other they have expectations about what is received and returned, which can be thought of as a contract between integrated endpoints.</li>
        <li>You can test internal services (microservices architecture) this way also, and use mocks and stubs for the expected returned values from the other system.</li>
    </ul>

    <h3>Integration Testing</h3>
    <ul>
        <li>This tests modules which have been unit tested, and aggregates them to test as a group.  Happens after unit testing,
            but before validation and system testing.
        </li>
        <li>Different methods can be used such as big-bang testing which combines large aggregates of modules, or can systematically
            test smaller aggregates first, building up to larger aggregates.
        </li>
        <li>Integration Testing is slower and more expensive on resources than unit testing, and should only be done once unit tests have been exhuasted.</li>
    </ul>

    <h3>UI Layer Testing</h3>
    <ul>
        <li></li>
    </ul>

    <h2>Mocha</h2>
    <ul>
        <li>Mocha is a javascript test framework, which should be installed using <code>npm install mocha -D</code> in the root directory of a project, to save it to the dev dependcies of the project (-D)</li>
        <li>Once installed, it can be executed from the project root directory with <code>./node_modules/mocha/bin/mocha</code>, however it is more common to set it as the test script
        in the project's package.json by setting <code>"test": "mocha"</code> in the scripts object, so mocha can be executed using <code>npm test</code>. This will run the full test suite instead of having
        to run each test in your test folder individually.  You can put <code>"test": "mocha test/**/*_test.js"</code> to specifically run anything in any folder of the test directory that ends in _test.</li>
        <li>Typically the architecture is you'll have a test folder in the root of your project, with one or more js files containing tests.  You might have an index.js file, and a corresponding index_test.js file in the test folder.  In the index_test.js you'll require in index.js at the top (and index.js will need a module.exports statement) so you can test the functionality in index.js.  You'll also typically require in the assert core module or other assertion library like chai.  You don't have to require in Mocha if its been installed as described above.</li>
        <li>The <code>describe()</code> and <code>it()</code> are mocha methods that provide structure to your test code.  They both accept two arguments, a descriptive string and a callback function.</li>
        <ul>
            <li><code>describe()</code> groups related tests together, generally grouping together a test suite. the first argument should describe the grouping, and the callback function contains the test code and may include nested
            describe() functions to create subgroups of tests</li>
            <li><code>it()</code> defines the actual tests, generally each one is a unit test or a test case.  the first argument should describes the functionality tested such as 'returns argument with highest value', and the callback function should
            define the test</li>
            <li>Example code: 
                <code><pre>
                    describe('Math', () => {
                        describe('.max', () => {
                            it('returns the argument with the highest value', () => {
                                // Your test goes here
                            });
                            it('returns -Infinity when no arguments are provided', () => {
                                // Your test goes here
                            });
                        });
                    });
                </pre></code>
            </li>
        </ul>
        <li>The <code>assert</code> library is a core node module, and is commonly used with Mocha to perform a test. (Chai is another commonly used assertion library with Mocha) It must be imported to the test file with <code>const assert = require('assert');</code></li>
        <ul>
            <li><code>assert.ok()</code> accepts a single conditional statement such as <code>assert.ok(myVar === 3)</code> and throws an AssertionError if condition is false.  This communciates to mocha that a test has failed and mocha then logs it to the console.</li>
            <li><code>assert.equal()</code> and <code>assert.strictEqual()</code> can and should (for a more expressive, easier to read test) be used instead of .ok() when you just want to test if two items are equal, .equal does a loose == comparison and .strictEqual does a strict === comparison. e.g. <code>assert.strictEqual(result, expected)</code> where typically the result/actual is put first and the expected second</li>
            <li><code>assert.deepEqual()</code> should be used when comparing equality between two objects or two arrays. Comparing distinct but identical objects or arrays with == or === will result in false, because the objects/arrays are not in the same location in memory.</li>
            <li>There are other assert methods for specific circumstances that should generally be used instead of the more generic ok() method for more expressive tests that are easier to read</li>     
            <li>Example Code:
                <code><pre>
                    describe('+', () => {
                        it('returns the sum of its arguments', () => {
                            // Write assertion here
                            assert.ok(3 + 4 === 7);
                        });
                    });
                </pre></code>
            </li>
        </ul>
        <li>Test Phases are a good way to organize the test code inside an it statement callback function, to make it more maintainable, readable, and expressive</li>
        <ul>
            <li>Setup: create any variables, conditions, etc. needed to perform your test</li>
            <li>Exercise: using your setup, execute the actual functionality being tested</li>
            <li>Verify: using the outcome of the excerise, compare to expected outcome, can write an if statement to make this comparison and throw error if it fails, but the assert library provides a more compact way of doing that, making the test more expressive.</li>
            <li>Teardown: not always needed, this resets any conditions changed during the test such as altering files or directory structure, changing read/write permissions for a file, editing database records.
                This ensures your test is isolated.
            </li>
            <li>Example Code:
                <code><pre>
                    describe('appendFileSync', () => {
                        it('writes a string to text file at given path name', () => {

                            // Setup
                            const path = './message.txt';
                            const str = 'Hello Node.js';
                            
                            // Exercise: write to file
                            fs.appendFileSync(path, str);

                            // Verify: compare file contents to string
                            const contents = fs.readFileSync(path);
                            assert.ok(contents.toString() === str);

                            // Teardown: delete path
                            fs.unlinkSync(path);
                        });
                    });
                </pre></code>
            </li>
        </ul>
        <li>Hooks are generally a better way to write setup and teardown code instead of including it directly in your it callback code.  Hooks are included inside the describe callback function along with the
            it function calls.  Hooks include <code>beforeEach(), afterEach(), before(), after()</code> and accept a single callback function as an argument.  For example, the provided callback function for afterEach() will
            run after every time an it callback runs in the same describe callback.  This is especially important to use for teardown code because it ensures the teardown code will run even if the it callback ends early
            due to an assertError or other error being thrown.  The teardown code would not run after the error if it was included in the it callback directly.
        </li>
        <ul>
            <li>Example code:
                <code><pre>
                    describe('example', () => {
                    
                        afterEach(() => {
                            // teardown goes here
                        });
                        
                        it('.sample', () => {
                            // test goes here
                        });
                    });
                </pre></code>
            </li>
        </ul>
    </ul>

    <h2>Jest</h2>
    <ul>
        <li>Jest is another javascript test framework and the default one used for React applications.  It needs to be installed for a project by initiliazing the project with npm (npm init) if it isn't already, and then running <code>npm install jest -D</code> to install to dev dependencies.  Then in your package.json file, under scripts, make sure you have <code>"scripts" : { "test": "jest" }</code> so that jest runs when you use the command <code>npm test</code>.  If you made a react project with create-react-app then jest should already be installed, and <code>npm test</code> should already be configured to run jest tests</li>
        <li>By default, jest expects all tests to be saved in a folder in your root directory called <code>__tests__</code>.  By some conventions, you name each test file as <code>functionalityToTest.spec.js</code> where functionalityToTest is any descriptive name of the functionality to be tested in the file and .spec is included as an old Ruby convention indicating the file is a specification of functionality.</li>
        <li>As with Mocha, the typical usage is that you would import the functionality with <code>myFunction = require('../myFile/myCode.js')</code> to test from some javascript file in your project (and export the functionality in that file using module.exports = myFunction), and then you can use that funcitonality in your test file to exercise/test it. You shouldn't need to import Jest in your test files in any way if you've installed it for the project as described above</li>
        <li>Basic test syntax is similar to Mocha.  Instead of it() you may see test(), but both can be used in Jest and they mean the exact same thing, test() is the official method and it() is an alias for it. Also, Jest provides a special syntax for exercising and verifying, namely <code>expect().toEqual()</code>, where expect() wraps what you want to test, accepting an argument like a call to a function being tested that gives some output, and toEqual() is the matcher function that accepts an argument that that output should be equal to.  There are other 'matcher' functions besides .toEqual() like .toThrowError(Error('expected error msg here')) depending on the nature of the verification</li>
        <li>With react, each component will have its own test file.  Within each test file, use the describe function at the top level to separate out various contexts, e.g. describe('rendering') to hold all testing related to rendered output, describe('callbacks') to hold all tests related to callbacks and interactions, describe('lifecycle') to hold all tests related to lifecycle methods, etc. Under each top level describe block, don't be afraid of nesting describe blocks for specific conditions. E.g. you could have three levels like so: describe('rendering') > describe('initial state') > describe('when there is an initial value') / describe('when there is no initial value').  For each it block, use only one assertion </li>
        <li>Example:
            <code><pre>
                describe("Filter function", () => {
                    test("it should filter by a search term (link)", () => {

                        // Setup
                        const input = [
                            { id: 1, url: "https://www.url1.dev" },
                            { id: 2, url: "https://www.url2.dev" },
                            { id: 3, url: "https://www.link3.dev" }
                        ];

                        const output = [{ id: 3, url: "https://www.link3.dev" }];

                        //Exercise and Verify
                        expect(filterByTerm(input, "link")).toEqual(output);
                    });
                });
            </pre></code>
        </li>
        <li><strong>Code Coverage: </strong>Jest provides a code coverage analysis feature.  This provides a report of how well your test files covers the file that is imported and tested.  If there are lines in the file that are never tested by your test file, then the report will indicate those lines and give percentage of lines covered, and some other info.  This coverage analysis can be run in a few ways.  You can run <code>npm test -- --coverage</code> to get a report in the command line after the test runs.  You can change your package.json scripts.test property from <code>"jest"</code> to <code>"jest --coverage</code> to always run the coverage report when you run <code>npm test</code>.  You can also instead add a separate new property to your package.json file outside of the scripts property that is <code>"jest": { "collectCoverage": true, "coverageReporters": ["html"] }</code> which will also always run the coverage report when you run <code>npm test</code> and the coverageReporters property can be left out to simply run reports in the command line, or included to instead print the reports to html files in a folder called 'coverage' in your root directory and which contain even more info than the command line report.</li>
        <li><strong>Snapshot Testing: </strong>You can install an additional library called react test renderer to use with jest to perform snapshot testing, which allows your tests to create snapshots of the rendered component throughout the test.  Each time you run the test, it will compare to the previous snapshot and let you know if there are any changes, which you can confirm are intentional or not.  If you used create-react-app to set up your app, then all you need to do is run <code>npm install react-test-renderer -D</code> in your root to install to dev dependencies. If you didn't use create-react-app there are additional steps.  You then import renderer from react-test-renderer in your test file to use it.  Snapshot testing is great to validate the rendered structure of a component, but should be used in conjustion with regular testing.  A basic use of snapshot testing would be to compare your component's rendered HTML to a stored snapshot of the rendered HTML from a previous render, so you can detect if anything has changed an decide if that was intentional or not.  The snapshot of the HTML will be stored in e.g. src/__snapshots__/App.test.js.snapshot, if you are creating the snapshots in your tests in the App.test.js file.  The snapshot is simply the HTML produced, and it shoudl be converted to JSON for making comparisons in the test. The first time you run the test in App.test.js the snapshot will not exist and it will automatically be created by renderer.create().  Future runs of the test will compare to this stored snapshot.  The test will fail if they don't match.  However, if you intended for the snapshot to change, then you simply press u in the terminal window where tests are being run to update the stored snapshot.
        <code><pre>
                // src/App.test.js
                import React from 'react';
                import renderer from 'react-test-renderer';
                import App from './App';
                
                it('matches the snapshot', () => {
                    const tree = renderer.create(&ltApp />).toJSON();
                    expect(tree).toMatchSnapshot();
                });
        </pre></code>
            
        Now, imagine you had e.g. a component called Link that lets you create custom links and that has methods called onMouseEnter and onMouseLeave that change a 'status' state variable indicating if the link is hovered over or not. You could have a test that calls those methods and takes a snapshot of the component after the method is called as so:
        <code><pre>
            // Link.react.test.js
            import React from 'react';
            import renderer from 'react-test-renderer';
            import Link from '../Link.react';

            test('Link changes the class when hovered', () => {
                const component = renderer.create(
                    &ltLink page="http://www.facebook.com">Facebook&lt/Link>,
                );
                let tree = component.toJSON();
                expect(tree).toMatchSnapshot();

                // manually trigger the callback
                tree.props.onMouseEnter();
                // re-rendering
                tree = component.toJSON();
                expect(tree).toMatchSnapshot();

                // manually trigger the callback
                tree.props.onMouseLeave();
                // re-rendering
                tree = component.toJSON();
                expect(tree).toMatchSnapshot();
            });
        </pre></code> This will create a snapshot file in your test folder called Link.react.test.js.snapshot and will include a snapshot of the HTML that the component rendered each time you call .toMatchSnapshot().  Next time you test, if the snapshots don't match you'll get an error.  You can override the error by running <code>jest -u</code> which will overwrite the existing snapshot.</li>
        <li>Jest Mocks: To test components that render complex child components (maybe they make API calls or access local storage) you can use jest.mock to create mocks of these components that replace the real thing when testing.  For example. suppose you had an App component that imports a component <code>import MyComponent from './MyComponent';</code> and renders MyComponent.  Suppose you want to test your App component, and MyComponent makes an API call that you don't need to test.  Your test could use jest.mock as follows:
        <code><pre>
            import React from 'react';
            import { render } from '@testing-library/react';
            import App from './App';

            jest.mock('./MyComponent', () => () => (&ltdiv>Hello World&lt/div>));

            test('renders', () => {
                const { container } = render(&ltApp/>);
                expect(container.textContent)
                    .toMatch('Hello World');
            });
        </pre></code>
        Alternatively you can create a separate file where you create the mock instead of defining it inline as above.  The file should be located in a folder next to the actual component you want to mock, e.g. the mock for ./MyComponent.js should be in ./__mocks__/MyComponent.js. when you call jest.mock on MyComponent, it will automatically find the mocked component when no inline mock is provided.  Thus the test is the same as above except the call to jest.mock should be <code>jest.mock('./MyComponent');</code> The mock should look like:
        <code><pre>
            import React from 'react';

            const MyMockComponent = () => (&ltdiv>Hello World&lt/div>);

            export default MyMockComponent;
        </pre></code></li>
    </ul>

    <h2>Enzyme</h2>
    <ul>
        <li>Enzyme is a testing library to help test the output of React components.  It needs to be installed in the project's root with <code>npm install enzyme enzyme-adapter-react-16 -D</code>, which actually is to install both the enzyme library and the adapater library that makes enzyme work with react v16.  You will install a different adapter library depending on the version of react you are using.  Using enzyme with react also depends on having react and react-dom installed which should be already for your react app.</li>
        <li>To use enzyme in tests, you need a setupTests.js file in your src/ folder, that tells enzyme what adapter to use.  create-react-app is configured to automatically run this file before running tests.  The file should include the following code:
            <code><pre>
                import Enzyme from 'enzyme';
                import Adapter from 'enzyme-adapter-react-16';

                Enzyme.configure({ adapter: new Adapter() });
            </pre></code>
        </li>
        <li>Enzyme works in tandem with test frameworks such as Mocha and Jest and assertion libraries, to handle the actual organization, running of tests.  Enzyme simply allows you to render React components in the test so that you can check various things about the render.  Full DOM rendering mounts the component in the DOM and is meant for when components interact with the DOM or for components wrapped in higher order components.  You should very rarely have a need to use full DOM (Mount) rendering because it runs your whole component tree and usually with tests you just should test one isolated component, and it also slows your tests down a lot due to the DOM rendering. Shallow rendering is a little less intensive and is what you should use 99% of the time, it is a simulated rendering of a component tree that doesn't require the DOM and only goes one level of components deep, allowing for testing of the component's rendered contents, and simulation of user interaction.  Static rendering seems to be least intensive and generates an HTML tree you can inspect.</li>
        <li>A basic content and user interaction test using enzyme for the App component would be stored at src/App.test.js.  It could first test the initial state of the component by making a shallow render of the App comoponent, saving it to the variable wrapper.  Shallow renders then have method you can use, e.g. to find a paragraph element in the component and get the innerHTML text of it.  Finally it can test that text is equal to an expected value. Next, it could test user interaction, say there is a button element rendered by App, and it has a className of 'increment'.  Enzyme can simulate a click of that button, and then you can again test the paragraph element to test it has the correct value after the click.  The code might look like this, being used here with Jest:
            <code><pre>
                    import React from 'react';
                    import { shallow } from 'enzyme';
                    import App from './App';
                    
                    describe('App component', () => {
                        it('starts with a count of 0', () => {
                            const wrapper = shallow(&ltApp />);
                            const text = wrapper.find('p').text();
                            expect(text).toEqual('Count: 0');
                        });
                        it('increments count by 1 when the increment button is clicked', () => {
                            const wrapper = shallow(&ltApp />);
                            const incrementBtn = wrapper.find('button.increment');
                            incrementBtn.simulate('click');
                            const text = wrapper.find('p').text();
                            expect(text).toEqual('Count: 1');
                        });
                    });
            </pre></code>
        </li>
        <li>More examples with Mocha/Chai:
            <h3>Shallow Rendering</h3>
            <code><pre>
                import React from 'react';
                import { expect } from 'chai';
                import { shallow } from 'enzyme';
                import sinon from 'sinon';

                import MyComponent from './MyComponent';
                import Foo from './Foo';

                describe('&ltMyComponent />', () => {
                it('renders three &ltFoo /> components', () => {
                    const wrapper = shallow(&ltMyComponent />);
                    expect(wrapper.find(Foo)).to.have.lengthOf(3);
                });

                it('renders an `.icon-star`', () => {
                    const wrapper = shallow(&ltMyComponent />);
                    expect(wrapper.find('.icon-star')).to.have.lengthOf(1);
                });

                it('renders children when passed in', () => {
                    const wrapper = shallow((
                    &ltMyComponent>
                        &ltdiv className="unique" />
                    &lt/MyComponent>
                    ));
                    expect(wrapper.contains(&ltdiv className="unique" />)).to.equal(true);
                });

                it('simulates click events', () => {
                    const onButtonClick = sinon.spy();
                    const wrapper = shallow(&ltFoo onButtonClick={onButtonClick} />);
                    wrapper.find('button').simulate('click');
                    expect(onButtonClick).to.have.property('callCount', 1);
                });
                });
            </pre></code>

            <h3>Full DOM Rendering</h3>
            <code><pre>
                import React from 'react';
                import sinon from 'sinon';
                import { expect } from 'chai';
                import { mount } from 'enzyme';

                import Foo from './Foo';

                describe('&ltFoo />', () => {
                it('allows us to set props', () => {
                    const wrapper = mount(&ltFoo bar="baz" />);
                    expect(wrapper.props().bar).to.equal('baz');
                    wrapper.setProps({ bar: 'foo' });
                    expect(wrapper.props().bar).to.equal('foo');
                });

                it('simulates click events', () => {
                    const onButtonClick = sinon.spy();
                    const wrapper = mount((
                    &ltFoo onButtonClick={onButtonClick} />
                    ));
                    wrapper.find('button').simulate('click');
                    expect(onButtonClick).to.have.property('callCount', 1);
                });

                it('calls componentDidMount', () => {
                    sinon.spy(Foo.prototype, 'componentDidMount');
                    const wrapper = mount(&ltFoo />);
                    expect(Foo.prototype.componentDidMount).to.have.property('callCount', 1);
                    Foo.prototype.componentDidMount.restore();
                });
                });
            </pre></code>

            <h3>Static Rendering</h3>
            <code><pre>
                import React from 'react';
                import { expect } from 'chai';
                import { render } from 'enzyme';

                import Foo from './Foo';

                describe('&ltFoo />', () => {
                it('renders three `.foo-bar`s', () => {
                    const wrapper = render(&ltFoo />);
                    expect(wrapper.find('.foo-bar')).to.have.lengthOf(3);
                });

                it('renders the title', () => {
                    const wrapper = render(&ltFoo title="unique" />);
                    expect(wrapper.text()).to.contain('unique');
                });
                });
            </pre></code>
        </li>
    </ul>
</body>
</html>